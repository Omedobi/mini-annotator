{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed420c26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0438a28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install labelImg\n",
    "import json\n",
    "import shutil\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import random \n",
    "import ipywidgets\n",
    "from tqdm import tqdm\n",
    "\n",
    "pd.set_option('Display.max_rows', None)\n",
    "pd.set_option('Display.max_columns', None)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.159  Python-3.9.18 torch-2.7.1+cpu CPU (Intel Core(TM) i7-8750H 2.20GHz)\n",
      "Setup complete  (12 CPUs, 23.9 GB RAM, 234.2/476.2 GB disk)\n"
     ]
    }
   ],
   "source": [
    "import ultralytics\n",
    "from ultralytics import YOLO\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36b4cbbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " 'data.yaml',\n",
       " 'runs',\n",
       " 'src',\n",
       " 'test',\n",
       " 'train',\n",
       " 'ui-detection.ipynb',\n",
       " 'ui-element-augmented',\n",
       " 'valid',\n",
       " 'yolov8m.pt',\n",
       " 'yolov8n.pt',\n",
       " '__init__.py']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_dir = \"C:\\\\Users\\\\Legion\\\\OneDrive\\\\Documents\\\\ML-Ops\\\\UI.Land Computer vision\\\\ui-element-detection\"\n",
    "\n",
    "\n",
    "#check for subfolders present\n",
    "os.listdir(root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.240 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.159  Python-3.9.18 torch-2.7.1+cpu CPU (Intel Core(TM) i7-8750H 2.20GHz)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=64, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=C:\\Users\\Legion\\OneDrive\\Documents\\ML-Ops\\UI.Land Computer vision\\ui-element-detection\\data.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8l.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs\\detect\\train, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=10\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
      "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n",
      "  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n",
      "  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n",
      "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  8                  -1  3   4461568  ultralytics.nn.modules.block.C2f             [512, 512, 3, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  3   1247744  ultralytics.nn.modules.block.C2f             [768, 256, 3]                 \n",
      " 16                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  3   4592640  ultralytics.nn.modules.block.C2f             [768, 512, 3]                 \n",
      " 19                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
      " 22        [15, 18, 21]  1   5590510  ultralytics.nn.modules.head.Detect           [10, [256, 512, 512]]         \n",
      "Model summary: 209 layers, 43,637,550 parameters, 43,637,534 gradients, 165.4 GFLOPs\n",
      "\n",
      "Transferred 589/595 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 188.455.9 MB/s, size: 31.3 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\Legion\\OneDrive\\Documents\\ML-Ops\\UI.Land Computer vision\\ui-element-detection\\train\\labels.cache... 7 images, 0 backgrounds, 0 corrupt: 100%|██████████| 7/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 135.477.1 MB/s, size: 23.5 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Legion\\OneDrive\\Documents\\ML-Ops\\UI.Land Computer vision\\ui-element-detection\\valid\\labels.cache... 2 images, 0 backgrounds, 0 corrupt: 100%|██████████| 2/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\detect\\train\\labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/20         0G      4.691      5.519      3.859         62        640: 100%|██████████| 1/1 [00:22<00:00, 22.68s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:02<00:00,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          2          9          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/20         0G      4.652      5.483      3.796         69        640: 100%|██████████| 1/1 [00:24<00:00, 24.08s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:02<00:00,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          2          9          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/20         0G      4.829       5.32      3.743         68        640: 100%|██████████| 1/1 [00:23<00:00, 23.51s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:02<00:00,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          2          9          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/20         0G      4.448       5.19      3.637         69        640: 100%|██████████| 1/1 [00:23<00:00, 23.83s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:02<00:00,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          2          9          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/20         0G      4.741      4.883       3.61         88        640: 100%|██████████| 1/1 [00:24<00:00, 24.48s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:02<00:00,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          2          9          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/20         0G      4.313      4.553      3.447         92        640: 100%|██████████| 1/1 [00:22<00:00, 22.56s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:02<00:00,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          2          9          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/20         0G      4.398      4.586      3.273         60        640: 100%|██████████| 1/1 [00:22<00:00, 22.70s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:02<00:00,  2.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          2          9          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/20         0G      4.356      4.463      3.298         94        640: 100%|██████████| 1/1 [00:23<00:00, 23.37s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:02<00:00,  2.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          2          9          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/20         0G      3.791      4.218      2.948         58        640: 100%|██████████| 1/1 [00:23<00:00, 23.68s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:02<00:00,  2.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          2          9          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/20         0G      3.929      3.792      3.026        104        640: 100%|██████████| 1/1 [00:23<00:00, 23.27s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:02<00:00,  2.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          2          9     0.0238      0.143     0.0711     0.0426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/20         0G      3.419      3.924      2.659         44        640: 100%|██████████| 1/1 [00:23<00:00, 23.00s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:02<00:00,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          2          9     0.0207      0.143      0.142     0.0497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/20         0G      3.273      3.616      2.726         43        640: 100%|██████████| 1/1 [00:22<00:00, 22.67s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:02<00:00,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          2          9      0.213      0.143      0.142     0.0426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/20         0G      3.142      3.679      2.848         36        640: 100%|██████████| 1/1 [00:22<00:00, 22.15s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:02<00:00,  2.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          2          9      0.212      0.143      0.142     0.0426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/20         0G       2.71      3.286      2.595         38        640: 100%|██████████| 1/1 [00:22<00:00, 22.66s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:02<00:00,  2.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          2          9      0.216      0.143      0.142     0.0426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/20         0G      2.722       3.36      2.402         39        640: 100%|██████████| 1/1 [00:26<00:00, 26.08s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          2          9      0.362      0.143      0.142     0.0426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/20         0G      2.547       2.87       2.32         41        640: 100%|██████████| 1/1 [00:29<00:00, 29.42s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          2          9      0.462      0.143     0.0474    0.00948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/20         0G      2.313       2.73      2.228         40        640: 100%|██████████| 1/1 [00:28<00:00, 28.05s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:02<00:00,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          2          9      0.467      0.143     0.0474     0.0142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/20         0G      2.443      2.888      2.401         32        640: 100%|██████████| 1/1 [00:26<00:00, 26.77s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:02<00:00,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          2          9      0.326      0.143     0.0489      0.015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/20         0G      2.349      2.582      2.245         40        640: 100%|██████████| 1/1 [00:24<00:00, 24.99s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:02<00:00,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          2          9      0.325      0.143     0.0487      0.015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/20         0G      2.201      2.596      2.097         43        640: 100%|██████████| 1/1 [00:24<00:00, 24.93s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:02<00:00,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          2          9      0.322      0.143     0.0487     0.0148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "20 epochs completed in 0.161 hours.\n",
      "Optimizer stripped from runs\\detect\\train\\weights\\last.pt, 87.7MB\n",
      "Optimizer stripped from runs\\detect\\train\\weights\\best.pt, 87.7MB\n",
      "\n",
      "Validating runs\\detect\\train\\weights\\best.pt...\n",
      "Ultralytics 8.3.159  Python-3.9.18 torch-2.7.1+cpu CPU (Intel Core(TM) i7-8750H 2.20GHz)\n",
      "Model summary (fused): 112 layers, 43,614,318 parameters, 0 gradients, 164.9 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          2          9     0.0215      0.143      0.142     0.0497\n",
      "           cancel icon          1          1          0          0          0          0\n",
      "            share icon          1          1       0.15          1      0.995      0.348\n",
      "                button          1          3          0          0          0          0\n",
      "          loading icon          1          1          0          0          0          0\n",
      "        hamburger icon          1          1          0          0          0          0\n",
      "             love icon          1          1          0          0          0          0\n",
      "           search icon          1          1          0          0          0          0\n",
      "Speed: 3.0ms preprocess, 1123.9ms inference, 0.0ms loss, 396.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#loading the model\n",
    "model = YOLO('yolov8l.pt')\n",
    "\n",
    "#train the model\n",
    "results = model.train(data=os.path.join(root_dir,\"data.yaml\"), device='cpu', epochs=20, batch=64, name='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results not found at C:\\Users\\Legion\\OneDrive\\Documents\\ML-Ops\\UI.Land Computer vision\\ui-element-detection\\runs\\detect\\train\\\n"
     ]
    }
   ],
   "source": [
    "# Visualize Training Results\n",
    "result_plot = \"C:\\\\Users\\\\Legion\\\\OneDrive\\\\Documents\\\\ML-Ops\\\\UI.Land Computer vision\\\\ui-element-detection\\\\runs\\\\detect\\\\train\\\\\"\n",
    "if os.path.exists(result_plot):\n",
    "    image = plt.imread(result_plot)\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(f\"Training results not found at {result_plot}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "32c6ed72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.159  Python-3.9.18 torch-2.7.1+cpu CPU (Intel Core(TM) i7-8750H 2.20GHz)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 56.627.5 MB/s, size: 432.2 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Legion\\OneDrive\\Documents\\ML-Ops\\UI.Land Computer vision\\ui-element-detection\\valid\\labels... 2 images, 4 backgrounds, 0 corrupt: 100%|██████████| 6/6 [00:00<00:00, 333.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Users\\Legion\\OneDrive\\Documents\\ML-Ops\\UI.Land Computer vision\\ui-element-detection\\valid\\labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING NMS time limit 2.300s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:07<00:00,  7.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          6          9    0.00235      0.143    0.00748     0.0028\n",
      "           cancel icon          1          1          0          0          0          0\n",
      "            share icon          1          1     0.0165          1     0.0524     0.0196\n",
      "                button          1          3          0          0          0          0\n",
      "          loading icon          1          1          0          0          0          0\n",
      "        hamburger icon          1          1          0          0          0          0\n",
      "             love icon          1          1          0          0          0          0\n",
      "           search icon          1          1          0          0          0          0\n",
      "Speed: 4.0ms preprocess, 832.3ms inference, 0.0ms loss, 441.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\valid3\u001b[0m\n",
      "Mean Average Precision (mAP): 0.002801783871443314\n",
      "Precision: [          0    0.016481           0           0           0           0           0]\n",
      "Recall: [          0           1           0           0           0           0           0]\n"
     ]
    }
   ],
   "source": [
    "#Model evaluation\n",
    "metrics = model.val(data=\"C:\\\\Users\\\\Legion\\\\OneDrive\\\\Documents\\\\ML-Ops\\\\UI.Land Computer vision\\\\ui-element-detection\\\\data.yaml\", name='valid')\n",
    "\n",
    "# Access specific metrics\n",
    "print(\"Mean Average Precision (mAP):\", metrics.box.map)  \n",
    "print(\"Precision:\", metrics.box.p)\n",
    "print(\"Recall:\", metrics.box.r)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model on new images\n",
    "model = YOLO(r'C:\\Users\\Legion\\OneDrive\\Documents\\ML-Ops\\mini-annotator\\notebook\\runs\\detect\\train\\weights\\best.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "40659cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in directory: ['ui-element1.jpg']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "test_dir = r\"C:\\Users\\Legion\\OneDrive\\Documents\\ML-Ops\\UI.Land Computer vision\\ui-element-detection\\test\\images\"\n",
    "\n",
    "# Check if the directory exists\n",
    "if not os.path.exists(test_dir):\n",
    "    raise FileNotFoundError(f\"Test directory not found: {test_dir}\")\n",
    "\n",
    "# List files in the directory\n",
    "files = os.listdir(test_dir)\n",
    "print(\"Files in directory:\", files)\n",
    "\n",
    "if not files:\n",
    "    raise FileNotFoundError(f\"No files found in the directory: {test_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "72d35d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/5 C:\\Users\\Legion\\OneDrive\\Documents\\ML-Ops\\UI.Land Computer vision\\ui-element-detection\\test\\images\\Screenshot_20240830_180646.png: 640x320 1 share icon, 51 input fields, 12 dropdowns, 503.8ms\n",
      "image 2/5 C:\\Users\\Legion\\OneDrive\\Documents\\ML-Ops\\UI.Land Computer vision\\ui-element-detection\\test\\images\\Screenshot_20240830_180710.png: 640x320 84 input fields, 4 dropdowns, 400.2ms\n",
      "image 3/5 C:\\Users\\Legion\\OneDrive\\Documents\\ML-Ops\\UI.Land Computer vision\\ui-element-detection\\test\\images\\Screenshot_20240830_180916.png: 640x320 42 input fields, 3 dropdowns, 401.0ms\n",
      "image 4/5 C:\\Users\\Legion\\OneDrive\\Documents\\ML-Ops\\UI.Land Computer vision\\ui-element-detection\\test\\images\\Screenshot_20240830_180928.png: 640x320 61 input fields, 12 dropdowns, 403.1ms\n",
      "image 5/5 C:\\Users\\Legion\\OneDrive\\Documents\\ML-Ops\\UI.Land Computer vision\\ui-element-detection\\test\\images\\ui-element1.jpg: 640x640 123 input fields, 683.5ms\n",
      "Speed: 2.9ms preprocess, 478.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\test_results2\u001b[0m\n",
      "ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: None\n",
      "names: {0: 'cancel icon', 1: 'share icon', 2: 'input field', 3: 'dropdown', 4: 'radio', 5: 'button', 6: 'loading icon', 7: 'hamburger icon', 8: 'love icon', 9: 'search icon'}\n",
      "obb: None\n",
      "orig_img: array([[[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       [[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       [[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       [[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       [[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]]], dtype=uint8)\n",
      "orig_shape: (1507, 720)\n",
      "path: 'C:\\\\Users\\\\Legion\\\\OneDrive\\\\Documents\\\\ML-Ops\\\\UI.Land Computer vision\\\\ui-element-detection\\\\test\\\\images\\\\Screenshot_20240830_180646.png'\n",
      "probs: None\n",
      "save_dir: 'runs\\\\detect\\\\test_results2'\n",
      "speed: {'preprocess': 3.392399999938789, 'inference': 503.7926000004518, 'postprocess': 0.8521999989170581}\n",
      "ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: None\n",
      "names: {0: 'cancel icon', 1: 'share icon', 2: 'input field', 3: 'dropdown', 4: 'radio', 5: 'button', 6: 'loading icon', 7: 'hamburger icon', 8: 'love icon', 9: 'search icon'}\n",
      "obb: None\n",
      "orig_img: array([[[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       [[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       [[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       [[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       [[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]]], dtype=uint8)\n",
      "orig_shape: (1507, 720)\n",
      "path: 'C:\\\\Users\\\\Legion\\\\OneDrive\\\\Documents\\\\ML-Ops\\\\UI.Land Computer vision\\\\ui-element-detection\\\\test\\\\images\\\\Screenshot_20240830_180710.png'\n",
      "probs: None\n",
      "save_dir: 'runs\\\\detect\\\\test_results2'\n",
      "speed: {'preprocess': 1.8421999993734062, 'inference': 400.2206000004662, 'postprocess': 1.4290999988588737}\n",
      "ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: None\n",
      "names: {0: 'cancel icon', 1: 'share icon', 2: 'input field', 3: 'dropdown', 4: 'radio', 5: 'button', 6: 'loading icon', 7: 'hamburger icon', 8: 'love icon', 9: 'search icon'}\n",
      "obb: None\n",
      "orig_img: array([[[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       [[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       [[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ...,\n",
      "        [ 41,  43,  43],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       [[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ...,\n",
      "        [ 40,  42,  42],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       [[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ...,\n",
      "        [ 39,  41,  41],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]]], dtype=uint8)\n",
      "orig_shape: (1507, 720)\n",
      "path: 'C:\\\\Users\\\\Legion\\\\OneDrive\\\\Documents\\\\ML-Ops\\\\UI.Land Computer vision\\\\ui-element-detection\\\\test\\\\images\\\\Screenshot_20240830_180916.png'\n",
      "probs: None\n",
      "save_dir: 'runs\\\\detect\\\\test_results2'\n",
      "speed: {'preprocess': 2.73159999960626, 'inference': 401.00079999865557, 'postprocess': 1.253000000360771}\n",
      "ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: None\n",
      "names: {0: 'cancel icon', 1: 'share icon', 2: 'input field', 3: 'dropdown', 4: 'radio', 5: 'button', 6: 'loading icon', 7: 'hamburger icon', 8: 'love icon', 9: 'search icon'}\n",
      "obb: None\n",
      "orig_img: array([[[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       [[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       [[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       [[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       [[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]]], dtype=uint8)\n",
      "orig_shape: (1507, 720)\n",
      "path: 'C:\\\\Users\\\\Legion\\\\OneDrive\\\\Documents\\\\ML-Ops\\\\UI.Land Computer vision\\\\ui-element-detection\\\\test\\\\images\\\\Screenshot_20240830_180928.png'\n",
      "probs: None\n",
      "save_dir: 'runs\\\\detect\\\\test_results2'\n",
      "speed: {'preprocess': 2.7638999999908265, 'inference': 403.1011999995826, 'postprocess': 1.3901999991503544}\n",
      "ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: None\n",
      "names: {0: 'cancel icon', 1: 'share icon', 2: 'input field', 3: 'dropdown', 4: 'radio', 5: 'button', 6: 'loading icon', 7: 'hamburger icon', 8: 'love icon', 9: 'search icon'}\n",
      "obb: None\n",
      "orig_img: array([[[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       [[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       [[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       [[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       [[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]]], dtype=uint8)\n",
      "orig_shape: (640, 640)\n",
      "path: 'C:\\\\Users\\\\Legion\\\\OneDrive\\\\Documents\\\\ML-Ops\\\\UI.Land Computer vision\\\\ui-element-detection\\\\test\\\\images\\\\ui-element1.jpg'\n",
      "probs: None\n",
      "save_dir: 'runs\\\\detect\\\\test_results2'\n",
      "speed: {'preprocess': 3.970800000388408, 'inference': 683.4675000009156, 'postprocess': 1.633899999433197}\n"
     ]
    }
   ],
   "source": [
    "# path to the test folder\n",
    "test_dir = r\"C:\\Users\\Legion\\OneDrive\\Documents\\ML-Ops\\UI.Land Computer vision\\ui-element-detection\\test\\images\"\n",
    "\n",
    "results = model.predict(source=test_dir, save=True, imgsz=640, conf=0.25, name='test_results')\n",
    "\n",
    "#show the result\n",
    "for result in results:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7c9975a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No predicted image found at //notebook//runs//detect//test_results\n"
     ]
    }
   ],
   "source": [
    "#Visualize Predictions\n",
    "predicted_image_path = '//notebook//runs//detect//test_results'  # Replace with an actual output path\n",
    "if predicted_image_path and os.path.exists(predicted_image_path):\n",
    "    image = cv2.imread(predicted_image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(f\"No predicted image found at {predicted_image_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422233b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648d262b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
